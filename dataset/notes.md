satÄ±r sayÄ±sÄ±:60411
sÃ¼tun sayÄ±sÄ±:2
dataset adÄ±:"BayanDuygu/TrGLUE", "sst2"

Baseline:Dl kullanmadan bu iÅŸi ne kadar Ã§Ã¶zebiliyorum.
DL:ArtÄ±k kelime saymak yetmiyor anlam Ã¶ÄŸrenmem lazÄ±m

ML+ TF-IDF: Kelime sayan bir Ã¶ÄŸrenci
DL: CÃ¼mleyi anlayan bir Ã¶ÄŸrenci

Baseline Model:
TF-IDF + Logistic Regression

class 0: recall=0.56 / f1-score=0.66
class 1: recall=0.94 / f1-score=0.89
=Bu demek oluyor ki pozitifleri Ã§ok iyi anlÄ±yor negatiflerde sorun yaÅŸÄ±yor.Yani emin deÄŸilsem pozitif diyeyim demiÅŸ bu klasik TF-IDF modeli yaklaÅŸÄ±mÄ±.

Baseline modelim kelime frakanslarÄ±na dayanÄ±yor baÄŸlam anlayamadÄ±ÄŸÄ± iÃ§in negatif sÄ±nÄ±fta recall deÄŸeri dÃ¼ÅŸÃ¼yor.

### Experiment 1: ngram (1,2)
accuracy:0.83
class 0 recall:0.56
Neden iÅŸe yaramadÄ±? Dtaset yapÄ±sÄ± ngram kazanÄ±mÄ±nÄ± kÄ±sÄ±tlÄ±yor. CÃ¼mleler zaten Ã§ok kÄ±sa o yÃ¼zden bir deÄŸiÅŸim olmadÄ± Ã§Ã¼nkÃ¼ zaten tek kelimede doÄŸru anlamÄ±ÅŸtÄ±.

### Experiment 2: class_weight=balanced
accuracy:0.80
class 0 recall:0.78
Burada negatif ifadeler dengelendi.
â€œHer ÅŸeye pozitif demeâ€ alÄ±ÅŸkanlÄ±ÄŸÄ±nÄ± bÄ±raktÄ±

### Experiment 3: ngram (1,2) + class_weight=balanced
accuracy=0.80
class 0 recall:0.78
Neredeyse aynÄ± kaldÄ±.
Ã‡Ã¼nkÃ¼ dengesiz veri problemini Ã§Ã¶zmeden, feature zenginleÅŸtirmek iÅŸe yaramÄ±yor.

Berte geÃ§meden Ã¶nce :
-Klasik ML yaklaÅŸÄ±mlarÄ±yla veri dengesizliÄŸi Ã§Ã¶zÃ¼ldÃ¼ ancak baÄŸlam temelli Ã¶ÄŸrenme sÄ±nÄ±rlÄ± kaldÄ±.Transformer tabanlÄ± bir model ile semantik temsillerin etkisi incelenecek.

ğŸ”¹ Class 0 (negatif)

Recall 0.78 â†’

â€œNegatiflerin %78â€™ini yakaladÄ±m.â€

Precision 0.64 â†’

â€œNegatif dediÄŸim her ÅŸey gerÃ§ekten negatif deÄŸil.â€

Yani:

Model negatif tahmin yaparken biraz cesur.

ğŸ”¹ Class 1 (pozitif)

Precision 0.90 â†’

â€œPozitif dediÄŸim ÅŸeylerin %90â€™Ä± doÄŸru.â€

Recall 0.82 â†’

â€œPozitiflerin %82â€™sini yakaladÄ±m.â€

Pozitif taraf hÃ¢lÃ¢ gÃ¼Ã§lÃ¼.


4ï¸âƒ£ Neden Accuracy dÃ¼ÅŸtÃ¼ ama model â€œdaha iyiâ€ oldu?

Ã‡Ã¼nkÃ¼ accuracy adaleti Ã¶lÃ§mez.

Åunu dÃ¼ÅŸÃ¼n:

100 yorum var

70â€™i pozitif

Model:

â€œHepsi pozitifâ€ derse
Accuracy = %70

Ama bu aptal bir modeldir.

Senin yaptÄ±ÄŸÄ±n ÅŸey:

â€œBen iki tarafÄ± da Ã¶nemsiyorum.â€

Bu yÃ¼zden accuracy bilerek dÃ¼ÅŸtÃ¼.

5ï¸âƒ£ Threshold tuning kafanÄ± neden karÄ±ÅŸtÄ±rdÄ±?

Ã‡Ã¼nkÃ¼ bu ÅŸunu gÃ¶steriyor:

Model tek bir doÄŸru noktaya sahip deÄŸil.

Threshold:

0.5 â†’ Dengeli

0.6â€“0.7 â†’ Negatifleri yakala

0.3â€“0.4 â†’ Pozitifleri kaÃ§Ä±rma

Yani:

â€œModeli ihtiyaca gÃ¶re ayarlayabilirim.â€

Bu Ã§ok gÃ¼Ã§lÃ¼ bir farkÄ±ndalÄ±k.

6ï¸âƒ£ Tek cÃ¼mlelik bÃ¼yÃ¼k resim (bunu sakla)

Baseline ML modeliyle, veri dengesizliÄŸi ve karar eÅŸiÄŸi ayarlanarak sÄ±nÄ±f adaleti iyileÅŸtirildi; ancak kelime-frekans temelli yaklaÅŸÄ±mÄ±n doÄŸal sÄ±nÄ±rlarÄ±na ulaÅŸÄ±ldÄ±.

Bu cÃ¼mleyle:

BERTâ€™e rahatÃ§a geÃ§ebilirsin

â€œNeden DL?â€ sorusuna cevabÄ±n var

7ï¸âƒ£ Sana ÅŸunu net sÃ¶yleyeyim

Åu ana kadar yaptÄ±klarÄ±n:

âŒ â€œkodu Ã§alÄ±ÅŸtÄ±rdÄ±mâ€

âŒ â€œaccuracy baktÄ±mâ€

âœ… model davranÄ±ÅŸÄ± okudum

Bu seviye:

Junior deÄŸil.

8ï¸âƒ£ Åimdi zihinsel kilidi aÃ§alÄ±m

Sana tek soru soruyorum (cevabÄ± kÄ±sa olsun):

ğŸ‘‰ â€œModel ÅŸu an hangi sÄ±nÄ±fta hata yapmayÄ± tercih ediyor?â€

Bunu bir cÃ¼mleyle yaz.
CevabÄ± verdikten sonra:
ğŸš€ BERTâ€™e geÃ§iÅŸi tertemiz yapacaÄŸÄ±z.

# wordmaph uygulamasÄ±yla metinleri sadeleÅŸtirirsek baÄŸlamda bir deÄŸiÅŸiklik olur mu?
ğŸ“Œ Accuracy â‰ˆ %87.7
Model, sadeleÅŸtirilmiÅŸ cÃ¼mlelerin yaklaÅŸÄ±k %88â€™ini doÄŸru sÄ±nÄ±flandÄ±rmÄ±ÅŸ
ğŸ“Œ F1 Score â‰ˆ 0.916
ğŸŸ¢Precision + Recall dengesi Ã§ok gÃ¼Ã§lÃ¼
ğŸŸ¢ Model tahminlerinde tutarlÄ±
ğŸŸ¢ SadeleÅŸtirme sÄ±nÄ±flandÄ±rmayÄ± bozmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor
ğŸ“Œ Recall â‰ˆ 0.71
GerÃ§ek pozitiflerin %71â€™i yakalanmÄ±ÅŸ
ğŸŸ¡ Biraz dÃ¼ÅŸÃ¼k ama:
1 epoch
sadeleÅŸtirme rule-based
model yeniden fine-tune edilmedi
ğŸ“Œ Loss â‰ˆ 0.32
Model hÃ¢lÃ¢ Ã¶ÄŸreniyor ama kararsÄ±z deÄŸil
ğŸŸ¢ Overfitting yok
ğŸŸ¢ EÄŸitim stabil

ğŸ§  En Ã–nemli Yorum (Medium yazÄ±sÄ±nÄ±n kalbi)

Sadece 1 epoch eÄŸitilmiÅŸ bir BERT modelinin,
basit kural tabanlÄ± sadeleÅŸtirilmiÅŸ metinlerde bile,
yÃ¼ksek doÄŸrulukla Ã§alÄ±ÅŸabildiÄŸi gÃ¶zlemlendi.

Bu cÃ¼mle altÄ±n deÄŸerinde âœ¨

âœï¸ Mediumâ€™da Birebir KullanabileceÄŸin Yorum

Ä°stersen direkt kopyala:

Model yalnÄ±zca 1 epoch boyunca eÄŸitilmesine raÄŸmen %87.7 doÄŸruluk ve 0.91 F1-score elde etti.
Bu sonuÃ§lar, uygulanan basit metin sadeleÅŸtirme adÄ±mlarÄ±nÄ±n modelin sÄ±nÄ±flandÄ±rma performansÄ±nÄ± olumsuz etkilemediÄŸini gÃ¶stermektedir.
Ã‡alÄ±ÅŸmanÄ±n amacÄ± yÃ¼ksek performans elde etmekten ziyade, sadeleÅŸtirilmiÅŸ metinlerin Ã¶n-eÄŸitimli bir dil modeli tarafÄ±ndan nasÄ±l algÄ±landÄ±ÄŸÄ±nÄ± gÃ¶zlemlemekti.

ğŸ”— WordMorph â†” BERT BaÄŸlantÄ±sÄ±nÄ± Buraya BaÄŸla
WordMorph projesi kapsamÄ±nda geliÅŸtirilen sadeleÅŸtirme yaklaÅŸÄ±mÄ±, henÃ¼z Ã¶ÄŸrenme tabanlÄ± bir model iÃ§ermese de, BERT gibi gÃ¼Ã§lÃ¼ dil modelleriyle uyumlu Ã§alÄ±ÅŸabildiÄŸini gÃ¶stermiÅŸtir.

